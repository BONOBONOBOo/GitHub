단일집단 비교검정

단일 집단을 대상으로 전 후에 대해 표본 추출해서 비율의 차이가 있는지 비교 검정(유의수준과 유의확률)

이항 분포 - binom.test()



단일 집단을 평군이 어떤 특정한 집단의 평균과의 차이를 검정을위해서 집단의 평균이 정규분포를 이루는지 

shapiro.test()



단일 집단의 평균이 정규 분포를 따르는 경우 t.test() (유의확률과 t검정 통계량)

단일 집단의 평균이 정규 분포를 따르지 않는 경우 wilcox.test()





두집단을 대상으로 비율 검정(독립표본 이항분포 비율 검정)		- prop.test(비율,표본 크기)

두집단을 대상으로 평균 검정 -> 두 집단의 평균의 정규분포가 동일한지 검정(동질성 검정)var.test()사용

->두집단의 평균의 정규분포를 따르는 경우 t.test()

->단일 집단의 평균이 정규 분포를 따르지 않는 경우 wilcox.test()



대응 두 집단(교수법 전, 교수법 후의 동일 대상의 서로 다른 점수)의 평균 차이 비교

대응 두 집단의 평균의 정규분포가 동일한지 검정(동질성 검정 -  var.test())

->두집단의 평균의 정규분포를 따르는 경우 t.test()

->단일 집단의 평균이 정규 분포를 따르지 않는 경우 wilcox.test()



세 집단 대상으로 비율 검정 - prop.test()

세 집단 대상으로 평균 검정 - 분산 분석,F검정

세 집단의 평균의 정규분포가 동일한지 검정 (동질성 검정 - bartlett.test())

세 집단의 평균이 정규 분포를 따르는 경우 aov()

세 집단의 정규분포를 따르지 않는 경우 - kruskal.test()

사후 검정 TukeyHSD



요인 분석

다수의 변수를 대상으로 변수간의 관게를 분석하여 결과를 이

상관분석이나 회귀분석의 설명변수(독립변수)로 활용하기 위해 수행하는 분석

변수의 주요 성분 분석 요인수를 알아 보려면 

1. 주성분 분석 - prcomp()
2. 고유값으로 요인수 분석 - 6개의 변수가 얼마나 연관성이있는지에관한 실수값 - eigen()

변수들간의 상관관계 분석으로 요인 분석 - 변수들간의 상관성을 이용해서 공통요인 추출 - factanal(dataset,factor="",rotation="")





```

###########요인분석 결과 요인 점수를 이용한 요인 적재량 시각화 ##########
# 6개 과목 (s1~s6) 
# 점수벡터 (5점 만점, 척도:5)
s1 <- c(1, 2, 1, 2, 3, 4, 2, 3, 4, 5)  #자연과학
s2 <- c(1, 3, 1, 2, 3, 4, 2, 4, 3, 4)  # 물리화학

s3 <- c(2, 3, 2, 3, 2, 3, 5, 3, 4, 2)  #인문사회
s4 <- c(2, 4, 2, 3, 2, 3, 5, 3, 4, 1)  # 신문방송

s5 <- c(4, 5, 4, 5, 2, 1, 5, 2, 4, 3)  #응용수학
s6 <- c(4, 3, 4, 4, 2, 1, 5, 2, 4, 2)  # 추론통계
name <-1:10  #각 과목의 문제 이름

#데이터 프레임 생성
subject <- data.frame(s1, s2, s3, s4, s5, s6)
str(subject)
result <- factanal(subject, factors=3, rotation="varimax" , scores="regression")
result

plot(result$scores[,c(1:2)],main="Factor1과 Factor2의 요인점수 행열")
text(result$scores[,1],result$scores[,2],labels=name,cex=0.7,pos=3,col="red")

points(result$loadings[, c(1:2)], pch=19, col="blue")
text(result$loadings[, 1], result$loadings[, 2], labels=rownames(result$loadings), cex=0.8, pos=3, col="blue")

install.packages("scatterplot3d")
require("scatterplot3d")

#요인 점수별로 분류
Factor1 <- result$scores[,1]
Factor2 <- result$scores[,2]
Factor3 <- result$scores[,3]

#scatterplot3d(밑변,오른쪽 변,왼쪽 변,type=)
d3 <- scatterplot3d(Factor1,Factor2,Factor3,type='p')

#요인 적재량 표시
loadings1 <- result$loadings[,1]
loadings2 <- result$loadings[,2]
loadings3 <- result$loadings[,3]
d3$points3d(loadings1, loadings2, loadings3, bg="red", pch=21, cex=2, type="h")

########요인 분석 결과를 이용하여  변수 묶기->  상관분석이나 회귀분석에서 독립변수로 사용할 수 있는 파생변수 생성 ####################
#Factor1 : 응용 과학
#Factor2 : 사회 과학
#Factor3 : 자연 과학

app <- data.frame(subject$s5, subject$s6)
soc <- data.frame(subject$s3, subject$s4)
net <- data.frame(subject$s1, subject$s2)

app_science <- round((app$subject.s5+app$subject.s6)/ncol(app),2)
soc_science <- round((soc$subject.s3 + soc$subject.s4)/ncol(soc), 2)
net_science <- round((net$subject.s1 + net$subject.s2)/ncol(net), 2)

app_science
soc_science
net_science

#상관관계 분석
subject_factor_df <- data.frame(app_science,soc_science,net_science)
cor(subject_factor_df)


################잘못 분류된 요인 제거로 변수 정제 #################
# 음료수 제품의 11개의 변수 (친밀도, 적절성, 만족도 3가지 영역)
# 특정 변수가 묶일 것으로 예상되는 요인이 묶이지 않는 경우,
# 해당 변수를 제거하는 정제 작업이 필요합니다.
install.packages("memisc")
require("memisc")
data.spss <- as.data.set(spss.system.file("./data/drinking_water.sav"))
data.spss 
# 제품 친밀도 (q1 : 브랜드, q2:친근감, q3:익숙함, q4:편안함)
# 제품 적절성 (q5 : 가격적절성, q6:당도적절성, q7:성분적절성)
# 제품 만족도 (q8 : 음료의 목넘김, q9:맛, q10:향 ,q11:가격)

drinking_water <- data.spss[1:11]  
drinking_water_df <- as.data.frame(data.spss[1:11])
str(drinking_water_df)

result <- factanal(drinking_water_df,factor=3,rotation = "varimax")
result

#Uniqueness는 11개의 변수가 0.5 이하의 값이면 모두 유효하다고 볼수있다.
#Loading : Factor1 (q8~q11), Factor2(q1~q3), Factor3(q4~q7)
#p-value는 0.255로 유의수준 0.05보다 작기 때문에 요인수 선택에 문제
#(p-value는 카이제곱검정의 결과로서 기대치와 관찰치에 차이가 있음을 알려주는 확률값)

# dw.df <- drinking_water_df[-4]
dw_df <- drinking_water_df[-4]
dw.df

s <- data.frame(dw.df$q8,dw.df$q9,dw.df$q10,dw.df$q11)
c <- data.frame(dw.df$q1,dw.df$q2,dw.df$q3)
p <- data.frame(dw.df$q5,dw.df$q6,dw.df$q7)

# satisfaction <- round((s$dw.df.q8+s$dw.df.q9+s$dw.df.q10+s$dw.df.q11)/ncol(s),2)
# closeness <- round((c$dw.df.q1+c$dw.df.q2+c$dw.df.q3)/ncol(c),2)
# pertinence <- round((p$dw.df.q5+p$dw.df.q6+p$dw.df.q7)/ncol(p),2)

satisfaction <-round( (dw_df$q8+dw_df$q9+dw_df$q10+dw_df$q11)/ncol(s), 2)
closeness <-round( (dw_df$q1+dw_df$q2+dw_df$q3)/ncol(c), 2)
pertinence <-round( (dw_df$q5+dw_df$q6+dw_df$q7)/ncol(p), 2)


dwf_df <- data.frame(satisfaction, closeness, pertinence)
colnames(dwf_df) <-c("제품 만족도", "제품 친밀도", "제품 적절성")
cor(dwf_df)


#해석> 제품 친밀도와 제품 적절성이 상관관계가 높은 변수들임

##########상관관계분석 #######################################
result <- read.csv("./data/product.csv", header=TRUE)
head(result)
str(result)

#요약정보 보여주는 함수들
summary(result)
sd(result$제품_친밀도)
sd(result$제품_적절성)
sd(result$제품_만족도)

cor(result$제품_만족도,result$제품_적절성)
cor(result$제품_친밀도+result$제품_적절성,result$제품_만족도)

#상관계수에따라 색의 농도로 시각화
install.packages("corrgram")
library("corrgram")
corrgram(result)
corrgram(result,upper.panel = panel.conf)#위쪽에 상관계수 추가
corrgram(result,lower.panel = panel.conf)#아래에 상관계수 추가

# 상관성, 밀도곡선, 유의확률 시각화
install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
# 상관성, p값(*), 정규분포 시각화
chart.Correlation(result, histogram=, pch="+")

# ##################상관 분석 연습문제################## #
# 다음은 drinkig_water_example.sav 파일의 데이터 셋이 구성된 테이블이다. 전체 2개의 요
# 인에 의해서 7개의 변수로 구성되어 있다. 아래에서 제시된 각 단계에 맞게 요인분석을 수행
# 하시오

# 요인 1001 (q1:브랜드, q2:친근감, q3: 익숙함)
# 제품 만족도 (q4:음료의 목 넘기, q5:음료의 맛, q6:음료의 향 , q7:가격)


# 베리멕스 회전법, 요인수 2, 요인점수 회귀분석 방법을 적용하여 요인분석 하시오
data.practice <- as.data.set(spss.system.file("./data/drinking_water_example.sav"))
drinking_water_df <- as.data.frame(data.practice[1:7])
str(drinking_water_df)
result <- factanal(drinking_water_df, factors=2, rotation="varimax",scores="regression")
result
result$scores

#요인별 변수로  묶기
s <- data.frame(drinking_water_df$q4,drinking_water_df$q5,drinking_water_df$q6,drinking_water_df$q7)
f <- data.frame(drinking_water_df$q1,drinking_water_df$q2,drinking_water_df$q3)

satisfac <- round((s$drinking_water_df.q4+s$drinking_water_df.q5+s$drinking_water_df.q6+s$drinking_water_df.q7)/ncol(s),2)
fac.1001 <- round((f$drinking_water_df.q1+f$drinking_water_df.q2+f$drinking_water_df.q3)/ncol(f),2)

# 요인적재량 행렬의 칼럼명 변경하시오 ("제품친밀도","제품만족도")
df <- data.frame(satisfac, fac.1001)
colnames(df) <-c("제품친밀도","제품만족도")


# 요인점수를 이용한 요인적재량 시각화하시오
plot(result$scores[, c(1:2)], main="Factor1과 Factor2의 요인점수 행렬")


# 생성된 두 개의 요인을 데이터프레임으로 생성한 후 이를 이용하여 두 요인 간
# 의 상관관계 계수를 제시하시오

head(df)
cor(df)


######################회귀 분석########################
product <- read.csv("./data/product.csv", header=TRUE)
head(product)
str(product)
product

y<-product$제품_만족도  #종속변수
x<-product$제품_적절성  #독립변수
df <- data.frame(x, y)

# 단순 선형회귀 모델 생성 lm(y~x, data)
library("stats")
result.lm <- lm(formula = y~x,data=df)
result.lm
# Y=0.7789 +0.7393*X
names(result.lm)
fitted.values(result.lm)[1:2]
head(df,1)

#Y=0.7789+0.7393*4
#Y=3.7361

#오차는 관측값 - 적합값
3 - 3.735963 #-0.735963
result <- residuals(result.lm)[1:2]

#선형회귀분석 모델 시각화
plot(formula=y~x, data=result)
abline(result.lm, col="red")   #회귀선

#선형회귀분석 결과
summary(result.lm)

# Multiple R-squared:  0.5881 는 독립변수에 의해서 종속변수가 얼마만큼 설명되었는가 (회귀모델의 설명력)
# Multiple R-squared 값은 독립변수와 종속변수 간의 상관관계를 나타내는 결정계수
# 설명력이 1에 가까울수록 설명변수(독립변수)가 설명을 잘한다고 판단할 수 있습니다. => 변수의 모델링이 잘 되었다는 의미

# Adjusted R-squared:  0.5865은 오차를 감안하여 조정된 R 값으로 (실제 분석은 이 값을 적용합니다.)

# F-statistic:   374 회귀모델의 적합성을 나타내며    
# p-value: < 2.2e-16 
# F-statistic와 p-value를 이용하여 회귀모델 자체를 신뢰할 수 있는지 판단
# p-value가 0.05보다 매우 작기 때문에 회귀선이 모델에 적합하다고 볼 수 있습니다.

#x            0.73928    0.03823  19.340  < 2e-16 ***
# x변수의 t=19.340 , p-value는 < 2e-16 이므로  p-value가 0.05보다 매우 작기 때문에 "제품의 가격과 품질을 결정하는 제품 적절성은 제품 만족도에 양의 영향을 미친다.
# " 연구가설 채택


###################### 다중 회귀 분석 ######################
product <- read.csv("./data/product.csv", header=TRUE)
head(product)
str(product)

y <- product$제품_만족도 # 종속 변수
x1 <- product$제품_적절성 # 독립 변수1
x2 <- product$제품_친밀도 # 독립 변수2
df <- data.frame(x1,x2,y)
df
#다중 회귀 분석
result.lm <- lm(formula = y~x1+x2,data=df)
result.lm

#다중 공선성 문제 확인
install.packages("car")
require("car")

vif(result.lm)#결과값이 10이상이면 다중공선성 문제를 의심해볼수있습니다.

#다중 회귀 분석 결과 보기
summary(result.lm)



# lm(formula = y ~ x1 + x2, data = df)
 
# Residuals:
#   Min       1Q   Median       3Q      Max 
# -2.01076 -0.22961 -0.01076  0.20809  1.20809 
 
# Coefficients:
#   Estimate Std. Error t value Pr(>|t|)    
# (Intercept)  0.66731    0.13094   5.096 6.65e-07 ***
#   x1           0.68522    0.04369  15.684  < 2e-16 ***
#   x2           0.09593    0.03871   2.478   0.0138 *  

# Residual standard error: 0.5278 on 261 degrees of freedom
# Multiple R-squared:  0.5975,	Adjusted R-squared:  0.5945 
# F-statistic: 193.8 on 2 and 261 DF,  p-value: < 2.2e-16

#x1는 제품의 적절성이 제품 만족도에 미치는 영향 t검정통계량 15.684, 
#x2는 제품의 친밀도가 제품 만족도에 미치는 영향 t검정통계량 2.478
# x1, x2의 유의 확률은 0.05보다 작기 때문에 제품 만족도에 양의 영향을 미친다(연구 가설 채택)

# 상관계수 0.5975 다소 높은 상관관계를 나타냄
# 조정된 설명력은 59.45%

# 회귀모델의 적합성은 f검정통계랑 : 193.8 p-value < 22e-16이므로 0.05보다 낮으므로 
# 이 회귀모델은 적합하다.



###다중 공선성 문제 해결하기###

attach(iris)
iris
#lm(formula = iris$Sepal.Length~iris$Sepal.Width+iris$Petal.Length+iris$Petal.Width)

fit <- lm(formula = Sepal.Length~Sepal.Width+Petal.Length+Petal.Width)

#다중공선성 문제 확인
vif(fit)
# Petal.Length, Petal.Width 변수는 강한 상관관계로 인해서 다중 공선성 문제가 의심된다

#다중공선성 문제가 의심되는 변수의 상관계수 확인
cor(iris[, -5])

#학습데이터와 검정 데이터를 7:3으로 표본 추출
x <- sample(1:nrow(iris),0.7*nrow(iris))
length(x)
train <- iris[x,]#학습데이터
test <- iris[-x,]
length(train$Sepal.Length)
length(test$Sepal.Length)
head(train,1)

#Petal.Width 변수를 제거한 후 학습데이터로부터 회귀모델 생성
model <- lm(formula= Sepal.Length ~ Sepal.Width+Petal.Length, data=iris)
summary(model)
vif(model)
model

# 꽃받침의 너비가 꽃받침의 길이에 영향을 미친다
# 꽃잎의 길이가 꽃받침의 길이에 영향을 준다

# 회귀 방정식
# Y=2.2491+0.5955+0.4719

#pred<-stats::predict(model,test)
pred<-predict(model,test)
pred

#모델 평가는 상관계수를 이용하여 모델의 정확도를 평가합니다.
cor(pred,test$Sepal.Length)
#예측치와 실제 관측치는 상관계수가 0.9291694이므로 매우 높은 상관관계를 갖고있습니다.
#모델의 정호가도가 아주 높다고 볼수있습니다.



################다중 회귀 분석 연습문제 #####################
# 01] product.csv 파일의 데이터를 이용하여 다음과 같은 단계로 다중회귀분석을 수행하시오.
product <- read.csv("./product2.csv", header=TRUE)

# 단계1 : 학습데이터(train), 검정데이터(test)를 7 : 3 비율로 샘플링
idx <- sample(1:nrow(product), 0.7*nrow(product))
train <- product[idx,] # result중 70%
dim(train) # [1] 184 3
train # 학습데이터
test <- product[-idx, ] # result중 나머지 30%
dim(test) # [1] 80 3
test # 검정 데이터


# 단계2 : 학습데이터 이용 회귀모델 생성
# 변수 모델링) y변수 : 제품_만족도, x변수 : 제품_적절성, 제품_친밀도
model <- lm(formula=제품_만족도 ~ 제품_적절성 + 제품_친밀도, data=train)
summary(model) # 학습데이터 분석 : p-value: < 2.2e-16


# 단계3 : 검정데이터 이용 모델 예측치 생성
pred <- predict(model, test) # 예측치 생성


# 단계4 : 모델 평가 : cor() 함수 이용
cor(pred, test$제품_만족도) # 모델 평가


#####################################################

# 문제02] ggplot2패키지에서 제공하는 diamonds 데이터 셋을 대상으로 carat, table, depth 변수
# 중 다이아몬드의 가격(price)에 영향을 미치는 관계를 다중회귀 분석을 이용하여 예측하
# 시오.
require("ggplot2")
attach(diamonds)
detach(diamonds)

fitt<- lm(formula = diamonds$price~diamonds$carat+diamonds$table+diamonds$depth)
summary(fit)

df <- data.frame(diamonds$price,diamonds$carat,diamonds$table,diamonds$depth)
vif(fitt)

cor(df)
# 조건1) 다이아몬드 가격 결정에 가장 큰 영향을 미치는 변수는?
# diamonds$carat

# 조건2) 다중회귀 분석 결과를 양(+)과 음(-) 관계로 해설


# 02] ggplot2패키지에서 제공하는 diamonds 데이터 셋을 대상으로 carat, table, depth 변수
# 중 다이아몬드의 가격(price)에 영향을 미치는 관계를 다중회귀 분석을 이용하여 예측하
# 시오.
# 조건1) 다이아몬드 가격 결정에 가장 큰 영향을 미치는 변수는?
#   조건2) 다중회귀 분석 결과를 양(+)과 음(-) 관계로 해설
# 
# library(ggplot2)
# data(diamonds)
# 
# # diamonds에서 비율척도 대상으로 식 작성
# formula <- price ~ carat + table + depth
# head(diamonds)
# result <- lm(formula, data=diamonds)
# summary(result) # 회귀분석 결과
# 
# #Coefficients:
# #Estimate Std. Error t value Pr(>|t|)
# #(Intercept) 13003.441 390.918 33.26 <2e-16 ***
# #carat 7858.771 14.151 555.36 <2e-16 ***
# #table -104.473 3.141 -33.26 <2e-16 ***
# #depth -151.236 4.820 -31.38 <2e-16 ***
# 해설>carat은 price에 정(+)의 영향을 미치지만, table과 depth는 부(-)의 영향을 미친다.


###################로지스틱 회귀분석 ############################
weather <- read.csv("./data/weather.csv", stringsAsFactors=F)
dim(weather)  # 관측치:366 ,  변수: 15
str(weather)

weather_df <- weather[, c(-1, -6, -8, -14)]

#y변수(RainTomorrow)의 로짓변환 : (0, 1)로 생성
weather_df$RainTomorrow[weather_df$RainTomorrow=='Yes']<-1
weather_df$RainTomorrow[weather_df$RainTomorrow=='No']<-0
weather_df$RainTomorrow <- as.numeric(weather_df$RainTomorrow)
head(weather_df)

#학습 데이터와 검정데이터 생성(7:3)
idx <- sample(1:nrow(weather_df), nrow(weather_df)*0.7)
train<- weather_df[idx, ]
test<- weather_df[-idx, ]

#학습 데이터로부터 로지스틱 회귀모델 생성
weather_model <- glm(formula=RainTomorrow ~., data=train, family='binomial')
summary(weather_model)

#로지스틱 회귀모델 예측치 생성
pred <- predict(weather_model,newdata=test,type="response")#response는 예측결과를 0~1사이의 확률값으로 예측치를 반환
pred    # 예측치가 1에 가까울수록 비율 확률이 높다고 할 수 있다

result_pred <- ifelse(pred>=0.5 , 1 , 0)
result_pred

table(result_pred) #0:96 1:13
table(result_pred,test$RainTomorrow)


# result_pred  0  1
#           0 88  8
#           1  6  7


# (88+7)/(88+8+6+7)

#ROC Curve 를 이용한 모델 평가
install.packages("ROCR")
library(ROCR)
pr <- prediction(pred, test$RainTomorrow)
prf <- performance(pr, measure="tpr", x.measure="fpr")
plot(prf)

#왼쪽 상단의 계단모양의 빈 공백만큼이 분류 정확도에서 오분류(missing)를 나타낸다.


```























